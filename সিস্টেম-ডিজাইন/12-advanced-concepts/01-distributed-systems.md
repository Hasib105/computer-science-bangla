# Distributed Systems Deep Dive

## ğŸ¯ Distributed System à¦•à¦¿?

**Distributed System** à¦¹à¦²à§‹ à¦à¦®à¦¨ à¦à¦•à¦Ÿà¦¿ à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦® à¦¯à§‡à¦–à¦¾à¦¨à§‡ à¦à¦•à¦¾à¦§à¦¿à¦• à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà¦¾à¦° à¦à¦•à¦¸à¦¾à¦¥à§‡ à¦•à¦¾à¦œ à¦•à¦°à§‡ à¦à¦•à¦Ÿà¦¿ unified system à¦¹à¦¿à¦¸à§‡à¦¬à§‡à¥¤

```
Single Machine:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Server               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ CPU â”‚ â”‚ RAM â”‚ â”‚ Diskâ”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Distributed System:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node 1  â”‚â”€â”€â”€â”€â”‚ Node 2  â”‚â”€â”€â”€â”€â”‚ Node 3  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚               â”‚               â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              Network
```

## ğŸ“Š Fallacies of Distributed Computing

```
à§®à¦Ÿà¦¿ à¦­à§à¦² à¦§à¦¾à¦°à¦£à¦¾ à¦¯à¦¾ à¦ªà§à¦°à§‹à¦—à§à¦°à¦¾à¦®à¦¾à¦°à¦°à¦¾ à¦•à¦°à§‡:

1. The network is reliable
   â†’ Packets drop, connections fail

2. Latency is zero
   â†’ Network calls take time (ms to seconds)

3. Bandwidth is infinite
   â†’ Data transfer has limits

4. The network is secure
   â†’ Man-in-the-middle, eavesdropping

5. Topology doesn't change
   â†’ Nodes come and go

6. There is one administrator
   â†’ Multiple teams, policies

7. Transport cost is zero
   â†’ Serialization, network fees

8. The network is homogeneous
   â†’ Different hardware, protocols
```

## ğŸ”„ Distributed System Challenges

### à§§. Network Partitions
```
Normal:
Node A â†â”€â”€â”€â”€â”€â”€â†’ Node B

Partition (Split-brain):
Node A    X    Node B
  â”‚             â”‚
  â†“             â†“
"I'm the      "I'm the
 leader"       leader"

à¦‰à¦­à¦¯à¦¼à¦‡ à¦®à¦¨à§‡ à¦•à¦°à§‡ à¦¸à§‡ leader!

Solution: Quorum-based decisions
```

### à§¨. Clock Synchronization
```
Problem:
Node A: 10:00:00.000
Node B: 10:00:00.050  (50ms ahead)
Node C: 09:59:59.990  (10ms behind)

Event ordering à¦•à¦ à¦¿à¦¨ à¦¹à¦¯à¦¼à§‡ à¦¯à¦¾à¦¯à¦¼!

Solutions:
â”œâ”€â”€ NTP (Network Time Protocol)
â”œâ”€â”€ Logical Clocks (Lamport)
â”œâ”€â”€ Vector Clocks
â””â”€â”€ Hybrid Logical Clocks (HLC)
```

### à§©. Byzantine Failures
```
Node à¦­à§à¦² à¦¤à¦¥à§à¦¯ à¦¦à¦¿à¦¤à§‡ à¦ªà¦¾à¦°à§‡ (malicious/buggy)

Normal Failure:
Node fails â†’ No response

Byzantine Failure:
Node responds with wrong/malicious data

Solution: Byzantine Fault Tolerance (BFT)
Requires: 3f + 1 nodes to tolerate f failures
```

## ğŸ—ï¸ Distributed System Patterns

### à§§. Leader Election
```
à¦•à§‹à¦¨ node decisions à¦¨à§‡à¦¬à§‡?

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Leader Election               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  Initial: All nodes are followers       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  F  â”‚  â”‚  F  â”‚  â”‚  F  â”‚  â”‚  F  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â”‚  Election: One becomes leader           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  L  â”‚â†â”€â”‚  F  â”‚â”€â”€â”‚  F  â”‚â”€â”€â”‚  F  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  Leader   Followers                     â”‚
â”‚                                         â”‚
â”‚  Leader fails: Re-election              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  X  â”‚  â”‚  L  â”‚â†â”€â”‚  F  â”‚â”€â”€â”‚  F  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  Dead    New Leader                     â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Algorithms: Bully, Ring, Raft, Paxos
```

### à§¨. Quorum
```
Majority agreement for decisionsà¥¤

N = 5 nodes
Quorum = âŒŠN/2âŒ‹ + 1 = 3

Write Quorum (W): Minimum nodes to confirm write
Read Quorum (R): Minimum nodes to read from

Strong Consistency: W + R > N

Example:
N=5, W=3, R=3
W + R = 6 > 5 âœ“

At least 1 node has latest data in any read.
```

### à§©. Gossip Protocol
```
Nodes randomly exchange informationà¥¤

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Gossip Protocol               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  Time T0: Node A has info               â”‚
â”‚  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”   â”‚
â”‚  â”‚ A*â”‚  â”‚ B â”‚  â”‚ C â”‚  â”‚ D â”‚  â”‚ E â”‚   â”‚
â”‚  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â”‚  Time T1: A tells B                     â”‚
â”‚  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”   â”‚
â”‚  â”‚ A*â”‚â”€â†’â”‚ B*â”‚  â”‚ C â”‚  â”‚ D â”‚  â”‚ E â”‚   â”‚
â”‚  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â”‚  Time T2: Aâ†’C, Bâ†’D                      â”‚
â”‚  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”   â”‚
â”‚  â”‚ A*â”‚â”€â†’â”‚ B*â”‚  â”‚ C*â”‚  â”‚ D*â”‚  â”‚ E â”‚   â”‚
â”‚  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”˜   â”‚
â”‚                                         â”‚
â”‚  Eventually: All nodes have info        â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Used by: Cassandra, DynamoDB, Consul
```

### à§ª. Crdt (Conflict-free Replicated Data Types)
```
Automatic conflict resolutionà¥¤

G-Counter (Grow-only Counter):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node A: {A: 5, B: 0, C: 0} = 5        â”‚
â”‚  Node B: {A: 0, B: 3, C: 0} = 3        â”‚
â”‚  Node C: {A: 0, B: 0, C: 2} = 2        â”‚
â”‚                                         â”‚
â”‚  Merge: {A: 5, B: 3, C: 2} = 10        â”‚
â”‚  (Take max of each)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

No conflicts possible!
Used by: Riak, Redis CRDT
```

## ğŸ“Š CAP Theorem Deep Dive

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CAP Theorem                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚           Consistency                   â”‚
â”‚               /\                        â”‚
â”‚              /  \                       â”‚
â”‚             /    \                      â”‚
â”‚            / CP   \                     â”‚
â”‚           /        \                    â”‚
â”‚          /    AP    \                   â”‚
â”‚         /            \                  â”‚
â”‚        /______________\                 â”‚
â”‚   Availability    Partition            â”‚
â”‚                   Tolerance             â”‚
â”‚                                         â”‚
â”‚  CP: MongoDB, HBase, Redis Cluster      â”‚
â”‚  AP: Cassandra, DynamoDB, CouchDB      â”‚
â”‚  CA: Traditional RDBMS (single node)    â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Network partition à¦¹à¦²à§‡ choose à¦•à¦°à¦¤à§‡ à¦¹à¦¯à¦¼:
- Consistency (reject some requests)
- Availability (serve potentially stale data)
```

## ğŸ”§ PACELC Theorem

```
CAP à¦à¦° extension:

If Partition (P):
  Choose Availability (A) or Consistency (C)
Else (E):
  Choose Latency (L) or Consistency (C)

Examples:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    System      â”‚ Partition â”‚   Else    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DynamoDB       â”‚    PA     â”‚    EL     â”‚
â”‚ Cassandra      â”‚    PA     â”‚    EL     â”‚
â”‚ MongoDB        â”‚    PC     â”‚    EC     â”‚
â”‚ MySQL (single) â”‚    PC     â”‚    EC     â”‚
â”‚ PNUTS (Yahoo)  â”‚    PC     â”‚    EL     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’¡ Design Considerations

```
Distributed System Design à¦•à¦°à¦¾à¦° à¦¸à¦®à¦¯à¦¼:

â–¡ Failure modes identify à¦•à¦°à§à¦¨
â–¡ Idempotent operations design à¦•à¦°à§à¦¨
â–¡ Retry with exponential backoff
â–¡ Circuit breaker pattern
â–¡ Timeout à¦¸à¦ à¦¿à¦•à¦­à¦¾à¦¬à§‡ set à¦•à¦°à§à¦¨
â–¡ Monitoring à¦“ observability
â–¡ Data consistency model choose à¦•à¦°à§à¦¨
â–¡ Partition tolerance plan à¦•à¦°à§à¦¨
```

## ğŸ“š à¦ªà¦°à¦¬à¦°à§à¦¤à§€ à¦Ÿà¦ªà¦¿à¦•

[Consensus Algorithms â†’](./02-consensus.md)
